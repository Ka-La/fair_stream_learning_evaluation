{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_synthesizer.DataDescriber import DataDescriber\n",
    "from data_synthesizer.DataGenerator import DataGenerator\n",
    "from data_synthesizer.ModelInspector import ModelInspector\n",
    "from data_synthesizer.lib.utils import read_json_file, display_bayesian_network\n",
    "from data_synthesizer.lib.PrivBayes import construct_noisy_conditional_distributions\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "description = f'/vol/kiakademie/stream_fairness_exp/student_performance_from_survey_description_full_por.json'\n",
    "clean_description = f'/vol/kiakademie/stream_fairness_exp/student_performance_from_survey_description_full_pordebiased.json'\n",
    "\n",
    "\n",
    "\n",
    "num_tuples_to_generate = 5000\n",
    "\n",
    "from DataManipulator import DataManipulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sex', ['activities', 'famsup']], ['schoolsup', ['sex']], ['school', ['schoolsup']], ['G1', ['school', 'sex']], ['address', ['school']], ['reason', ['school']], ['failures', ['G1']], ['G2', ['G1']], ['G3', ['G1', 'G2']], ['age', ['failures']], ['higher', ['G1', 'age']], ['guardian', ['age']], ['romantic', ['age']], ['Pstatus', ['guardian']], ['famsize', ['Pstatus']], ['nursery', ['famsize']], ['traveltime', ['address']], ['Mjob', ['internet']], ['Medu', ['Mjob']], ['Fedu', ['Medu']], ['Fjob', ['Fedu']], ['internet', ['school', 'address']]]\n"
     ]
    }
   ],
   "source": [
    "describer = DataDescriber()\n",
    "describer.data_description = read_json_file(description)\n",
    "bayesian_net = describer.data_description['bayesian_network']\n",
    "\n",
    "print(bayesian_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_values(description, parent):\n",
    "    parent_values = {}\n",
    "    bins = description['attribute_description'][parent]['distribution_bins']\n",
    "    for i in range(len(bins)):\n",
    "        parent_values[bins[i]] = i\n",
    "    \n",
    "    return parent_values\n",
    "\n",
    "def get_parent_indices(bn, child):\n",
    "    parent_indices = {}\n",
    "\n",
    "    for entry in bn:\n",
    "        if entry[0] == child:\n",
    "            i = 0\n",
    "            for parent in entry[1]:\n",
    "                parent_indices[parent] = i\n",
    "                i += 1\n",
    "    return parent_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': 0}\n"
     ]
    }
   ],
   "source": [
    "parent_indices = get_parent_indices(bayesian_net, 'schoolsup')\n",
    "print(parent_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 0, 'yes': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_parent_values(description=describer.data_description, parent='schoolsup'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': 0, 'M': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_parent_values(description=describer.data_description, parent='sex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 0, 'yes': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_parent_values(description=describer.data_description, parent='internet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 4: 1, 5: 2, 6: 3, 7: 4, 8: 5, 9: 6, 10: 7, 11: 8, 12: 9, 13: 10, 14: 11, 15: 12, 16: 13, 17: 14, 18: 15, 19: 16}\n"
     ]
    }
   ],
   "source": [
    "print(get_parent_values(description=describer.data_description, parent='G1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inducing drift for G1\n",
      "Inducing drift for G2\n"
     ]
    }
   ],
   "source": [
    "manipulator = DataManipulator()\n",
    "\n",
    "out_file = f'./data/student_performance/student_grade_inflation_on_unmodified_scenario_description.json'\n",
    "\n",
    "#probability *0.5 for grades 0-7, prob *1.5 for grades 14-19\n",
    "scenario_grade_inflation = {'G2': {'dist':[0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 1.5 ,1.5, 1.5, 1.5, 1.5, 1.0]}, \n",
    "                            'G1': {'dist':[0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 1.5 ,1.5, 1.5, 1.5, 1.5, 1.0]},} #increase probability of good grades acorss the board for G2 and G1\n",
    "changing_attributes = ['G1', 'G2']\n",
    "\n",
    "manipulator.induce_data_drift(description_file=description, out_file=out_file, changing_attributes=changing_attributes, add_dist=scenario_grade_inflation, non_disc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inducing drift for schoolsup\n",
      "0 [1]\n",
      "0 is not used for drift because parent values are [1]\n",
      "0 [1]\n"
     ]
    }
   ],
   "source": [
    "manipulator = DataManipulator()\n",
    "\n",
    "out_file = f'./data/student_performance/student_males_more_support_on_unmodified_scenario_description.json'\n",
    "\n",
    "scenario_male_support = {'schoolsup': {'dist':[0.0, 2.0], 'parent_indices': [0], 'parent_values' : {0 : [1]} }} #increase schoolsupport for male students\n",
    "changing_attributes = ['schoolsup']\n",
    "\n",
    "manipulator.induce_data_drift(description_file=description, out_file=out_file, changing_attributes=changing_attributes, add_dist=scenario_male_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inducing drift for schoolsup\n",
      "0 [0]\n",
      "0 [0]\n",
      "1 is not used for drift because parent values are [0]\n"
     ]
    }
   ],
   "source": [
    "manipulator = DataManipulator()\n",
    "\n",
    "out_file = f'./data/student_performance/student_females_more_support_on_unmodified_scenario_description.json'\n",
    "\n",
    "scenario_female_support = {'schoolsup': {'dist':[0.0, 2.0], 'parent_indices': [0], 'parent_values' : {0 : [0]} }} #increase schoolsupport for female students\n",
    "changing_attributes = ['schoolsup']\n",
    "\n",
    "manipulator.induce_data_drift(description_file=description, out_file=out_file, changing_attributes=changing_attributes, add_dist=scenario_female_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inducing drift for internet\n"
     ]
    }
   ],
   "source": [
    "manipulator = DataManipulator()\n",
    "\n",
    "out_file = f'./data/student_performance/student_internet_era_on_unmodified_scenario_description.json'\n",
    "\n",
    "scenario_internet_era = {'internet': {'dist':[0.0, 1.0]}} #everyone gets internet\n",
    "changing_attributes = ['internet']\n",
    "\n",
    "manipulator.induce_data_drift(description_file=description, out_file=out_file, changing_attributes=changing_attributes, add_dist=scenario_internet_era, non_disc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arff_head(description):\n",
    "    for attribute in description['meta']['all_attributes']:\n",
    "        if not attribute in description['meta']['candidate_keys']:\n",
    "            bins = description['attribute_description'][attribute]['distribution_bins']\n",
    "\n",
    "            val_string = \"{ \"\n",
    "\n",
    "            for val in bins[:-1]:\n",
    "                val_string += (str(val) + \", \")\n",
    "\n",
    "            val_string += (str(bins[-1]) + \"}\")\n",
    "\n",
    "            print(\"@attribute \" + attribute + \" \" + val_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@attribute school { GP, MS}\n",
      "@attribute sex { F, M}\n",
      "@attribute age { 15, 16, 17, 18, 19, 20, 21, 22}\n",
      "@attribute address { R, U}\n",
      "@attribute famsize { GT3, LE3}\n",
      "@attribute Pstatus { A, T}\n",
      "@attribute Medu { 0, 1, 2, 3, 4}\n",
      "@attribute Fedu { 0, 1, 2, 3, 4}\n",
      "@attribute Mjob { at_home, health, other, services, teacher}\n",
      "@attribute Fjob { at_home, health, other, services, teacher}\n",
      "@attribute reason { course, home, other, reputation}\n",
      "@attribute guardian { father, mother, other}\n",
      "@attribute traveltime { 1, 2, 3, 4}\n",
      "@attribute studytime { 1, 2, 3, 4}\n",
      "@attribute failures { 0, 1, 2, 3}\n",
      "@attribute schoolsup { no, yes}\n",
      "@attribute famsup { no, yes}\n",
      "@attribute paid { no, yes}\n",
      "@attribute activities { no, yes}\n",
      "@attribute nursery { no, yes}\n",
      "@attribute higher { no, yes}\n",
      "@attribute internet { no, yes}\n",
      "@attribute romantic { no, yes}\n",
      "@attribute famrel { 1, 2, 3, 4, 5}\n",
      "@attribute freetime { 1, 2, 3, 4, 5}\n",
      "@attribute goout { 1, 2, 3, 4, 5}\n",
      "@attribute Dalc { 1, 2, 3, 4, 5}\n",
      "@attribute Walc { 1, 2, 3, 4, 5}\n",
      "@attribute health { 1, 2, 3, 4, 5}\n",
      "@attribute absences { 0.0, 1.6, 3.2, 4.800000000000001, 6.4, 8.0, 9.600000000000001, 11.200000000000001, 12.8, 14.4, 16.0, 17.6, 19.200000000000003, 20.8, 22.400000000000002, 24.0, 25.6, 27.200000000000003, 28.8, 30.400000000000002}\n",
      "@attribute G1 { 0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "@attribute G2 { 0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "@attribute G3 { 0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n"
     ]
    }
   ],
   "source": [
    "generate_arff_head(describer.data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data for arff format - note: head needs to be once manually perfected with data from above ;)\n",
    "#also, all the inputs  except for the arff_head are INCOMPLETE paths, as this gets done for multiple repetitions in here (maybe I should do it in an outer loop? Whatever...)\n",
    "\n",
    "def create_arffs(in_csv, arff_head, temp_middle_csv, out_arff):\n",
    "\n",
    "    for repetition in range(10):\n",
    "        df = pd.read_csv(f\"{in_csv}{repetition}.csv\", index_col=False)\n",
    "        data = df.to_dict(orient='records')\n",
    "        new_data = []\n",
    "        for i in range(len(data)):\n",
    "            entry = data[i]\n",
    "            new_entry = {}\n",
    "            for k in entry.keys():\n",
    "                if k in ['G1', 'G2', 'G3']:\n",
    "                    if int(entry[k]) < 10:\n",
    "                        value = 0\n",
    "                    elif int(entry[k]) >= 10:\n",
    "                        value = 1\n",
    "                else:\n",
    "                    value = entry[k]\n",
    "                if value is None or value == '':\n",
    "                    value = '?'\n",
    "                new_entry[k] = value\n",
    "            new_data.append(new_entry)\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        new_df.to_csv(f\"{temp_middle_csv}{repetition}.csv\", index=False)\n",
    "\n",
    "\n",
    "        filenames = [f\"{arff_head}\",f\"{temp_middle_csv}{repetition}.csv\"]\n",
    "        with open(f\"{out_arff}{repetition}.arff\", 'w') as outfile:\n",
    "            i = 0\n",
    "            for fname in filenames:\n",
    "                with open(fname) as infile:\n",
    "                    j = 0\n",
    "                    for line in infile:\n",
    "                        if not j<i:\n",
    "                            outfile.write(line)\n",
    "                        j += 1\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 gets processed\n",
      "school gets processed\n",
      "sex gets processed\n",
      "age gets processed\n",
      "address gets processed\n",
      "famsize gets processed\n",
      "Pstatus gets processed\n",
      "Medu gets processed\n",
      "Fedu gets processed\n",
      "Mjob gets processed\n",
      "Fjob gets processed\n",
      "reason gets processed\n",
      "guardian gets processed\n",
      "traveltime gets processed\n",
      "studytime gets processed\n",
      "failures gets processed\n",
      "schoolsup gets processed\n",
      "famsup gets processed\n",
      "paid gets processed\n",
      "activities gets processed\n",
      "nursery gets processed\n",
      "higher gets processed\n",
      "internet gets processed\n",
      "romantic gets processed\n",
      "famrel gets processed\n",
      "freetime gets processed\n",
      "goout gets processed\n",
      "Dalc gets processed\n",
      "Walc gets processed\n",
      "health gets processed\n",
      "absences gets processed\n",
      "G1 gets processed\n",
      "G2 gets processed\n",
      "G3 gets processed\n",
      "Index(['Unnamed: 0', 'school', 'sex', 'age', 'address', 'famsize', 'Pstatus',\n",
      "       'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime',\n",
      "       'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities',\n",
      "       'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime',\n",
      "       'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scenario = 'grade_inflation'\n",
    "generator = DataGenerator()\n",
    "generator.generate_dataset_in_correlated_attribute_mode(num_tuples_to_generate, f'./data/student_performance/student_{scenario}_on_unmodified_scenario_description.json')\n",
    "generator.save_synthetic_data(f\"./data/student_performance/{scenario}.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(f'./data/student_performance/{scenario}.csv', index_col = False)\n",
    "print(df.columns)\n",
    "df.drop([\"Unnamed: 0\", \"G1\", \"G2\"], axis=1,inplace=True)\n",
    "\n",
    "for repetition in range(10):\n",
    "    df = shuffle(df)\n",
    "    df.dropna(inplace=True)\n",
    "    df.to_csv(f\"./data/student_performance/{scenario}/run_{repetition}.csv\", index=False)\n",
    "\n",
    "\n",
    "in_csv = f\"./data/student_performance/{scenario}/run_\"\n",
    "arff_head = f\"./data/student_performance/arff_head.arff\"\n",
    "tem_middle_csv = f\"./data/student_performance/{scenario}_preprocessed/run_\"\n",
    "out_arff = f\"./data/student_performance/{scenario}_preprocessed/run_\"\n",
    "\n",
    "create_arffs(in_csv, arff_head=arff_head, temp_middle_csv=tem_middle_csv, out_arff=out_arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data for arff format - note: head needs to be once manually perfected with data from above ;)\n",
    "#also, all the inputs  except for the arff_head are INCOMPLETE paths, as this gets done for multiple repetitions in here (maybe I should do it in an outer loop? Whatever...)\n",
    "\n",
    "#MODIFIED - High class only for 14+ instead of 10+ !!!\n",
    "\n",
    "def create_arffs_diff_class(in_csv, arff_head, temp_middle_csv, out_arff):\n",
    "\n",
    "    for repetition in range(10):\n",
    "        df = pd.read_csv(f\"{in_csv}{repetition}.csv\", index_col=False)\n",
    "        data = df.to_dict(orient='records')\n",
    "        new_data = []\n",
    "        for i in range(len(data)):\n",
    "            entry = data[i]\n",
    "            new_entry = {}\n",
    "            for k in entry.keys():\n",
    "                if k in ['G1', 'G2', 'G3']:\n",
    "                    if int(entry[k]) < 14:\n",
    "                        value = 0\n",
    "                    elif int(entry[k]) >= 14:\n",
    "                        value = 1\n",
    "                else:\n",
    "                    value = entry[k]\n",
    "                if value is None or value == '':\n",
    "                    value = '?'\n",
    "                new_entry[k] = value\n",
    "            new_data.append(new_entry)\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        new_df.to_csv(f\"{temp_middle_csv}{repetition}.csv\", index=False)\n",
    "\n",
    "\n",
    "        filenames = [f\"{arff_head}\",f\"{temp_middle_csv}{repetition}.csv\"]\n",
    "        with open(f\"{out_arff}{repetition}.arff\", 'w') as outfile:\n",
    "            i = 0\n",
    "            for fname in filenames:\n",
    "                with open(fname) as infile:\n",
    "                    j = 0\n",
    "                    for line in infile:\n",
    "                        if not j<i:\n",
    "                            outfile.write(line)\n",
    "                        j += 1\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scenario = 'grade_category_adjusted'\n",
    "\n",
    "in_csv = f\"./data/student_performance/unmodified/run_\"\n",
    "arff_head = f\"./data/student_performance/arff_head.arff\"\n",
    "tem_middle_csv = f\"./data/student_performance/{scenario}_preprocessed/run_\"\n",
    "out_arff = f\"./data/student_performance/{scenario}_preprocessed/run_\"\n",
    "\n",
    "create_arffs_diff_class(in_csv, arff_head=arff_head, temp_middle_csv=tem_middle_csv, out_arff=out_arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(pre_data_path, post_data_path, name, driftpoint, arff_head):\n",
    "\n",
    "    for i in range(10):\n",
    "        pre_drift = pd.read_csv(pre_data_path + \"/run_\" + str(i) +\".csv\")\n",
    "        post_drift = pd.read_csv(post_data_path + \"/run_\" + str(i) +\".csv\")\n",
    "\n",
    "        pre_df = pre_drift.iloc[:driftpoint,:]\n",
    "        post_df = post_drift.iloc[driftpoint:,:]\n",
    "\n",
    "        new = pd.concat([pre_df, post_df])\n",
    "        new.to_csv(name + \"/run_\" + str(i) + \".csv\", index=False)\n",
    "\n",
    "        filenames = [f\"{arff_head}\",f\"{name}/run_{i}.csv\"]\n",
    "        with open(f\"{name}/run_{i}.arff\", 'w') as outfile:\n",
    "            i = 0\n",
    "            for fname in filenames:\n",
    "                with open(fname) as infile:\n",
    "                    j = 0\n",
    "                    for line in infile:\n",
    "                        if not j<i:\n",
    "                            outfile.write(line)\n",
    "                        j += 1\n",
    "                i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'grade_inflation'\n",
    "\n",
    "arff_head = f\"./data/student_performance/arff_head.arff\"\n",
    "\n",
    "pre = f\"./data/student_performance/unmodified\"\n",
    "post = f\"./data/student_performance/{scenario}_preprocessed\"\n",
    "\n",
    "driftpoint = 2000\n",
    "name = f\"./data/student_performance/unmodified_to_{scenario}_{driftpoint}\"\n",
    "\n",
    "try:\n",
    "    Path.mkdir(f\"./data/student_performance/unmodified_to_{scenario}_{driftpoint}\")\n",
    "except Exception as e:\n",
    "    print(\"An error occured: \" + str(e))\n",
    "\n",
    "merge_datasets(pre_data_path=pre, post_data_path=post, name=name, driftpoint=driftpoint, arff_head=arff_head)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
